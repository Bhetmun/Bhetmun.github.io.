{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa02b1ef",
   "metadata": {},
   "source": [
    "## Machine Learning By Example Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f47d8a",
   "metadata": {},
   "source": [
    "### Task 1-2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70da0676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "\n",
    "assert sys.version_info >= (3,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95592d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('font', size=14) #general font size\n",
    "plt.rc('axes', labelsize=14, titlesize=14) #font size for the titles of x and y axes\n",
    "plt.rc('legend', fontsize=14) # font size for legends\n",
    "plt.rc('xtick', labelsize=10) # the font size of labels for intervals marked on the x axis\n",
    "plt.rc('ytick', labelsize=10) # the font size of labels for intervals marked on the y axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5139d3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "IMAGES_PATH = Path() / \"images\" / \"classification\"\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2c46e4",
   "metadata": {},
   "source": [
    "## Task 1-4\n",
    "\n",
    "#### How framing the problem affects data selection \n",
    "Firstly, the articles show that one of the important steps with framing our problem is so that we have clarity in what our objective is. This in turn helps us determine what the role of our model will be clearly and allows us to better select the right machine learning algorithm for the task. The readings suggest that a well defined task also helps with guiding the collection and preparation of data, if we do not define our problem and objectives, how can we collect data that has meaning. Also, understanding the task helps identify potential ethical considerations associated with the use of machine learning as demonstrated in the AI facial recognition article. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209c80cc",
   "metadata": {},
   "source": [
    "#### Selecting Algorithm \n",
    "Regression would be better suited for predicting median house pricing because the output is quantities that are based on the input of the model. \n",
    "\n",
    "Classification would be better suited for handwritten digit recognition because of multi-class classification which would be involved in the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36332c4e",
   "metadata": {},
   "source": [
    "## Task 2-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe62e98d",
   "metadata": {},
   "source": [
    "#### Downloading example tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2367b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "def load_housing_data(): \n",
    "    tarball_path = Path(\"datasets/housing.tgz\") \n",
    "    if not tarball_path.is_file():\n",
    "        Path(\"datasets\").mkdir(parents=True, exist_ok=True) \n",
    "        url = \"https://github.com/ageron/data/raw/main/housing.tgz\" \n",
    "        urllib.request.urlretrieve(url, tarball_path) \n",
    "        with tarfile.open(tarball_path) as housing_tarball: \n",
    "            housing_tarball.extractall(path=\"datasets\") \n",
    "    return pd.read_csv(Path(\"datasets/housing/housing.csv\")) \n",
    "\n",
    "housing = load_housing_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b498e9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9040cf2",
   "metadata": {},
   "source": [
    "There are 10 attributes and one of them ocean_proximity is not numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4e32e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"ocean_proximity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0413bf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.hist(bins=50, figsize=(12, 8))\n",
    "save_fig(\"attribute_histogram_plots\")  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1839b23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3d41c1",
   "metadata": {},
   "source": [
    "## Task 2-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac76a91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import pandas as pd\n",
    "\n",
    "mnist = fetch_openml('mnist_784', as_frame=False, parser='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f33687",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (mnist.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0148c22c",
   "metadata": {},
   "source": [
    "## Task 2-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650465da",
   "metadata": {},
   "source": [
    "***Mark Down cell for critique***\n",
    "\n",
    "1. Data transformation was done by transforming the originial NIST dataset of black and white images by size-normalising the digits and using anti-aliasing for grey levels\n",
    "2. They selected subsets from NIST, with SD-3 designated as the training set and SD-1 as the test set by considering factors like cleanliness and recognisability \n",
    "3. The MNIST training set was formed by combining 30,000 patterns from SD-3 and 30,00 patterns from SD-1, the test set comprised 5000 patterns from each  \n",
    "4. The decisions made were justified as they aimed to address issues related to data quality, standardisation and independence of training and test sets. These are useful for a reliable evaluation of machine learning models.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22e3a0d",
   "metadata": {},
   "source": [
    "## Task 2-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaf3066",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b592ae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = mnist.data\n",
    "categories = mnist.target\n",
    "\n",
    "print(\"Shape of Images:\", images.shape)\n",
    "\n",
    "print(\"Categories\", categories.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ef2aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def plot_digit(image_data): \n",
    "    image = image_data.reshape(28, 28) \n",
    "    plt.imshow(image, cmap=\"binary\") \n",
    "    plt.axis(\"off\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52759abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_digit = mnist.data[0]\n",
    "plot_digit(some_digit)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cea3576",
   "metadata": {},
   "source": [
    "## Task 3: Setting aside test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155b3fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tratio = 0.2 \n",
    "\n",
    "train_set, test_set = train_test_split(housing, test_size=tratio, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d91c70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "sample_size = 1000\n",
    "ratio_female = 0.511\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "samples = (np.random.rand(100_000, sample_size) < ratio_female).sum(axis=1)\n",
    "((samples < 485) | (samples > 535)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12316fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
    "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                               labels=[1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeadd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tratio = 0.2 \n",
    "\n",
    "strat_train_set, strat_test_set = train_test_split(housing, test_size=tratio, stratify=housing[\"income_cat\"], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef900dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5625f5",
   "metadata": {},
   "source": [
    "### Why is a stratified sample based on median income reasonable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f96d20",
   "metadata": {},
   "source": [
    "***Markdown cell***\n",
    "\n",
    "1. Stratified sampling based on median income ensures that each stratum is adequately represented in the sample, helping to capture the diversity of the population in terms of economic diversity. \n",
    "2. Stratified sampling can lead to a more precise estimation each income group. Particularly important for anaylsing subpopulations ith specific income characteristics.\n",
    "3. Provides proportional representation of each income stratum which ensures fairness in the presentation of different socioeconomic groups \n",
    "4. The results of a stratified sample are more likely to generalise well into the overall population. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16204082",
   "metadata": {},
   "source": [
    "### Task 3.2: Setting aside test set for image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5256ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mnist.data[:60000]\n",
    "y_train = mnist.target[:60000]\n",
    "\n",
    "X_test = mnist.data[60000:]\n",
    "y_test = mnist.target[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127d8f0a",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac5658a",
   "metadata": {},
   "source": [
    "### Step 1 Checking correlations: training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbb1f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5040ab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = housing.corr(numeric_only=True) \n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26619ba6",
   "metadata": {},
   "source": [
    "### Step 2: Visualise Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de9d62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "features = [\"median_house_value\", \"median_income\", \"total_rooms\",\n",
    "              \"housing_median_age\"]\n",
    "scatter_matrix(housing[features], figsize=(12, 8))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd39eef3",
   "metadata": {},
   "source": [
    "### Step 3: Separate the target labels from data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfd23a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.drop(\"median_house_value\", axis=1) \n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda56ad2",
   "metadata": {},
   "source": [
    "### Step 4: Look for missing values in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf60b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50ed975",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = housing.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2088b3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_total_bedrooms = missing_values['total_bedrooms']\n",
    "\n",
    "print(\"Number of missing values for 'total_bedrooms':\", missing_total_bedrooms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc7f4e4",
   "metadata": {},
   "source": [
    "### Step 5: Handling missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6855dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\") \n",
    "\n",
    "housing_num = housing.select_dtypes(include=[np.number])\n",
    "\n",
    "imputer.fit(housing_num) \n",
    "\n",
    "housing_num[:] = imputer.transform(housing_num) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38daf4e9",
   "metadata": {},
   "source": [
    "#### Comments\n",
    "It seems like using SimpleImputer to fill in the missing values with the median is the most straightforward way to deal with the problem but it seems like potentially you are oversimplifying your data by filling missing values with the median. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a11ffc3",
   "metadata": {},
   "source": [
    "### Step 6: Scaling features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e1350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_num.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b85b7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "housing_num_std_scaled = std_scaler.fit_transform(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acbc120",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_num[:]=std_scaler.fit_transform(housing_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2dd86a",
   "metadata": {},
   "source": [
    "### Step 7 Train a linear regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e87df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_scaler = StandardScaler()\n",
    "scaled_labels = target_scaler.fit_transform(housing_labels.to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56655105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression #get the library from sklearn.linear model\n",
    "\n",
    "model = LinearRegression() #get an instance of the untrained model\n",
    "model.fit(housing_num, scaled_labels)\n",
    "model.fit(housing[[\"median_income\"]], scaled_labels) \n",
    "some_new_data = housing[[\"median_income\"]].iloc[:5] \n",
    "\n",
    "scaled_predictions = model.predict(some_new_data)\n",
    "predictions = target_scaler.inverse_transform(scaled_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b64ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_new_data = housing_num.iloc[:5] \n",
    "some_new_data = housing[[\"median_income\"]].iloc[:5]  \n",
    "\n",
    "scaled_predictions = model.predict(some_new_data)\n",
    "predictions = target_scaler.inverse_transform(scaled_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bc05a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions, housing_labels.iloc[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254d7e69",
   "metadata": {},
   "source": [
    "### Step 8 Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f4e175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rmses = -cross_val_score(model, housing_num, scaled_labels,\n",
    "                              scoring=\"neg_root_mean_squared_error\", cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7850c81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(rmses).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d993b5a2",
   "metadata": {},
   "source": [
    "## Task 4: Hand written digit classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cab54e",
   "metadata": {},
   "source": [
    "### Step 1 Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e26d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e7e3e7",
   "metadata": {},
   "source": [
    "### Reviewing what the data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9223e1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(mnist))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75397e0",
   "metadata": {},
   "source": [
    "### Step 3 how to get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd51d09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbdcd21",
   "metadata": {},
   "source": [
    "### Step 4 Scaling the pixel values (the features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04d518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = X_train_full / 255.\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea45f9f1",
   "metadata": {},
   "source": [
    "### Step 5 Split the training data into training and validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f8a881",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
    "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8741a781",
   "metadata": {},
   "source": [
    "### increasing the dimension to include color channels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e247fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "X_train = X_train[..., np.newaxis] \n",
    "X_valid = X_valid[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fef6a0",
   "metadata": {},
   "source": [
    "### Step 6 building the neural network and fit it to the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1926be3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248a5cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f751b5",
   "metadata": {},
   "source": [
    "### Step 7 Training and evaluating the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f575ce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dd3dc8",
   "metadata": {},
   "source": [
    "### data from scikitlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5275b509",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "import pandas as pd\n",
    "\n",
    "mnist = fetch_openml('mnist_784', as_frame=False, parser='auto')\n",
    "\n",
    "\n",
    "images = mnist.data\n",
    "categories = mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4969bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "accuracy = cross_val_score(sgd_clf, images, categories, cv=10)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beda850d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
